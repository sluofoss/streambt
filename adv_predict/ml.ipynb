{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as db\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"/home/sean/Projects/streambt/full_df_2_exit.parquet/\")\n",
    "full_df = pd.concat(\n",
    "    pd.read_parquet(parquet_file)\n",
    "    for parquet_file in data_dir.glob('*.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\n",
    "\"\"\"\n",
    "select Ticker, year(Date) as yr, stddev_samp(log(Volume+1)) as std_vol\n",
    "from full_df\n",
    "group by Ticker, year(Date)\n",
    "having std_vol > 0 and yr = 2023\n",
    "order by std_vol desc\n",
    "\"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\n",
    "\"\"\"\n",
    "select Ticker, stddev_samp(log(Volume+1)) as std_vol\n",
    "from full_df\n",
    "group by Ticker\n",
    "order by std_vol desc\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021 asx 200 list\n",
    "string = \"\"\"\n",
    "(\n",
    "  'A2M.AX'\n",
    ", 'AAA.AX'\n",
    ", 'ABC.AX'\n",
    ", 'ABP.AX'\n",
    ", 'AFI.AX'\n",
    ", 'AGL.AX'\n",
    ", 'AIA.AX'\n",
    ", 'ALD.AX'\n",
    ", 'ALL.AX'\n",
    ", 'ALQ.AX'\n",
    ", 'ALU.AX'\n",
    ", 'ALX.AX'\n",
    ", 'AMC.AX'\n",
    ", 'AMP.AX'\n",
    ", 'ANN.AX'\n",
    ", 'ANZ.AX'\n",
    ", 'APA.AX'\n",
    ", 'APE.AX'\n",
    ", 'APT.AX'\n",
    ", 'APX.AX'\n",
    ", 'ARB.AX'\n",
    ", 'ARG.AX'\n",
    ", 'AST.AX'\n",
    ", 'ASX.AX'\n",
    ", 'AWC.AX'\n",
    ", 'AZJ.AX'\n",
    ", 'BAP.AX'\n",
    ", 'BEN.AX'\n",
    ", 'BGA.AX'\n",
    ", 'BHP.AX'\n",
    ", 'BIN.AX'\n",
    ", 'BKW.AX'\n",
    ", 'BLD.AX'\n",
    ", 'BOQ.AX'\n",
    ", 'BPT.AX'\n",
    ", 'BRG.AX'\n",
    ", 'BSL.AX'\n",
    ", 'BWP.AX'\n",
    ", 'BXB.AX'\n",
    ", 'CAR.AX'\n",
    ", 'CBA.AX'\n",
    ", 'CCL.AX'\n",
    ", 'CCP.AX'\n",
    ", 'CDA.AX'\n",
    ", 'CGF.AX'\n",
    ", 'CHC.AX'\n",
    ", 'CHN.AX'\n",
    ", 'CIA.AX'\n",
    ", 'CIM.AX'\n",
    ", 'CLW.AX'\n",
    ", 'CMW.AX'\n",
    ", 'CNU.AX'\n",
    ", 'COH.AX'\n",
    ", 'COL.AX'\n",
    ", 'CPU.AX'\n",
    ", 'CQR.AX'\n",
    ", 'CSL.AX'\n",
    ", 'CSR.AX'\n",
    ", 'CTD.AX'\n",
    ", 'CWN.AX'\n",
    ", 'CWY.AX'\n",
    ", 'DEG.AX'\n",
    ", 'DHG.AX'\n",
    ", 'DMP.AX'\n",
    ", 'DOW.AX'\n",
    ", 'DRR.AX'\n",
    ", 'DXS.AX'\n",
    ", 'EBO.AX'\n",
    ", 'ELD.AX'\n",
    ", 'EML.AX'\n",
    ", 'EVN.AX'\n",
    ", 'EVT.AX'\n",
    ", 'FBU.AX'\n",
    ", 'FLT.AX'\n",
    ", 'FMG.AX'\n",
    ", 'FPH.AX'\n",
    ", 'GMG.AX'\n",
    ", 'GNE.AX'\n",
    ", 'GOZ.AX'\n",
    ", 'GPT.AX'\n",
    ", 'GXY.AX'\n",
    ", 'HLS.AX'\n",
    ", 'HVN.AX'\n",
    ", 'IAG.AX'\n",
    ", 'IEL.AX'\n",
    ", 'IFL.AX'\n",
    ", 'IFT.AX'\n",
    ", 'IGO.AX'\n",
    ", 'ILU.AX'\n",
    ", 'IOO.AX'\n",
    ", 'IOZ.AX'\n",
    ", 'IPL.AX'\n",
    ", 'IRE.AX'\n",
    ", 'IVV.AX'\n",
    ", 'JBH.AX'\n",
    ", 'JHX.AX'\n",
    ", 'LFG.AX'\n",
    ", 'LFS.AX'\n",
    ", 'LLC.AX'\n",
    ", 'LNK.AX'\n",
    ", 'LYC.AX'\n",
    ", 'MCY.AX'\n",
    ", 'MEZ.AX'\n",
    ", 'MFG.AX'\n",
    ", 'MGF.AX'\n",
    ", 'MGO.AX'\n",
    ", 'MGR.AX'\n",
    ", 'MIN.AX'\n",
    ", 'MLT.AX'\n",
    ", 'MP1.AX'\n",
    ", 'MPL.AX'\n",
    ", 'MQG.AX'\n",
    ", 'MTS.AX'\n",
    ", 'NAB.AX'\n",
    ", 'NCM.AX'\n",
    ", 'NEC.AX'\n",
    ", 'NHF.AX'\n",
    ", 'NIC.AX'\n",
    ", 'NSR.AX'\n",
    ", 'NST.AX'\n",
    ", 'NUF.AX'\n",
    ", 'NWL.AX'\n",
    ", 'NXT.AX'\n",
    ", 'ORA.AX'\n",
    ", 'ORE.AX'\n",
    ", 'ORG.AX'\n",
    ", 'ORI.AX'\n",
    ", 'OSH.AX'\n",
    ", 'OZL.AX'\n",
    ", 'PBH.AX'\n",
    ", 'PDL.AX'\n",
    ", 'PLS.AX'\n",
    ", 'PME.AX'\n",
    ", 'PMG.AX'\n",
    ", 'PMV.AX'\n",
    ", 'PNI.AX'\n",
    ", 'PNV.AX'\n",
    ", 'PPT.AX'\n",
    ", 'PTM.AX'\n",
    ", 'QAN.AX'\n",
    ", 'QBE.AX'\n",
    ", 'QUB.AX'\n",
    ", 'REA.AX'\n",
    ", 'REH.AX'\n",
    ", 'RHC.AX'\n",
    ", 'RIO.AX'\n",
    ", 'RMD.AX'\n",
    ", 'RRL.AX'\n",
    ", 'RWC.AX'\n",
    ", 'S32.AX'\n",
    ", 'SCG.AX'\n",
    ", 'SCP.AX'\n",
    ", 'SDF.AX'\n",
    ", 'SEK.AX'\n",
    ", 'SGM.AX'\n",
    ", 'SGP.AX'\n",
    ", 'SGR.AX'\n",
    ", 'SHL.AX'\n",
    ", 'SKC.AX'\n",
    ", 'SKI.AX'\n",
    ", 'SLK.AX'\n",
    ", 'SNZ.AX'\n",
    ", 'SOL.AX'\n",
    ", 'SPK.AX'\n",
    ", 'STO.AX'\n",
    ", 'STW.AX'\n",
    ", 'SUL.AX'\n",
    ", 'SUN.AX'\n",
    ", 'SVW.AX'\n",
    ", 'SYD.AX'\n",
    ", 'TAH.AX'\n",
    ", 'TCL.AX'\n",
    ", 'TLS.AX'\n",
    ", 'TLT.AX'\n",
    ", 'TNE.AX'\n",
    ", 'TPG.AX'\n",
    ", 'TWE.AX'\n",
    ", 'TYR.AX'\n",
    ", 'VAP.AX'\n",
    ", 'VAS.AX'\n",
    ", 'VCX.AX'\n",
    ", 'VEA.AX'\n",
    ", 'VEU.AX'\n",
    ", 'VGS.AX'\n",
    ", 'VOC.AX'\n",
    ", 'VTS.AX'\n",
    ", 'VUK.AX'\n",
    ", 'WAM.AX'\n",
    ", 'WBC.AX'\n",
    ", 'WEB.AX'\n",
    ", 'WES.AX'\n",
    ", 'WOR.AX'\n",
    ", 'WOW.AX'\n",
    ", 'WPL.AX'\n",
    ", 'WPR.AX'\n",
    ", 'WTC.AX'\n",
    ", 'XRO.AX'\n",
    ", 'YAL.AX'\n",
    ", 'Z1P.AX'\n",
    ", 'ZIM.AX'\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_target = db.sql(\n",
    "f\"\"\"\n",
    "select \n",
    "    TMF_w\n",
    "    , TMF_4w_min\n",
    "    , TMF_4w_min_dd\n",
    "    , TMF_26w_min\n",
    "    , TMF_26w_min_dd\n",
    "    , TMF_4w_min_dd_qtl_50\n",
    "    , TMF_4w_min_dd_qtl_50_alt\n",
    "    , TMF_26w_min_dd_qtl_50\n",
    "    , TMF_26w_min_dd_qtl_50_alt \n",
    "    --, TMF_Simple_Signal\n",
    "    --, macd_hof\n",
    "    --, macd_signal_hof\n",
    "    --, macd_w_hof\n",
    "    --, macd_w_signal_hof\n",
    "    --, Volume\n",
    "    , stddev_samp(log(Volume+1)) over (partition by Ticker order by Date rows between 5*52 preceding and current row) as std_vol\n",
    "    , log(Volume + 1)\n",
    "    --, dayofweek(Date) as day_of_week\n",
    "    , Date\n",
    "    , Ticker\n",
    "    , case \n",
    "        when gain_loss_ratio2 > 1.01 then 1 \n",
    "        --when gain_loss_ratio2 > 1.0 then 0\n",
    "        else -1 \n",
    "    end as target\n",
    "from full_df\n",
    "where TMF_Simple_Signal = 1\n",
    "--and Ticker in string \n",
    "\"\"\"\n",
    ")\n",
    "train = db.sql(\"select * from feature_target where year(Date) in (2005,2007,2009,2011,2013,2015)\").df()\n",
    "\n",
    "print(train.columns)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "\n",
    "#clf = DecisionTreeClassifier(max_depth=5,class_weight={0:10,1:1})\n",
    "clf = RandomForestClassifier(n_estimators= 10,max_depth=20)\n",
    "#clf = RandomForestClassifier(n_estimators= 10,max_depth=50, class_weight={0:10,1:1})\n",
    "#clf = RandomForestClassifier(n_estimators= 10,max_depth=10)\n",
    "#clf = RandomForestClassifier(n_estimators= 10,max_depth=10, class_weight={0:10,1:1})\n",
    "#clf = RandomForestClassifier(n_estimators= 2,max_depth=10)#, class_weight={0:10,1:1})\n",
    "#clf = RandomForestClassifier(n_estimators= 50,max_depth=10, class_weight={0:10,1:1})\n",
    "\n",
    "clf.fit(train.drop(columns = ['Date', 'Ticker', 'target']),train['target'])\n",
    "\n",
    "s_train = clf.score(train.drop(columns = ['Date', 'Ticker', 'target']),train['target'])\n",
    "print(s_train)\n",
    "print(confusion_matrix(train['target'],clf.predict(train.drop(columns = ['Date', 'Ticker', 'target']))))\n",
    "print(precision_score(train['target'],clf.predict(train.drop(columns = ['Date', 'Ticker', 'target'])), average = 'weighted' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2018, 2021+1):\n",
    "    test  = db.sql(f\"select * from feature_target where year(Date) in ({year})\").df()\n",
    "    s_test = clf.score(test.drop(columns = ['Date', 'Ticker', 'target']),test['target'])\n",
    "    print(\"====================================\")\n",
    "    print(year)\n",
    "    print(sum(test['target']),len(test['target']))\n",
    "    print('----------------------')\n",
    "    print(s_test)\n",
    "    print(confusion_matrix(test['target'],clf.predict(test.drop(columns = ['Date', 'Ticker', 'target']))))\n",
    "    #print(precision_score(test['target'],clf.predict(test.drop(columns = ['Date', 'Ticker', 'target'])), average = 'weighted'))\n",
    "    print(precision_score(test['target'],clf.predict(test.drop(columns = ['Date', 'Ticker', 'target'])), average = 'binary'))\n",
    "    print(\"====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = db.sql(\n",
    "\"\"\"\n",
    "select * \n",
    "from feature_target \n",
    "where (year(Date)  >= 2018) and (year(Date) < 2021)\n",
    "\"\"\"\n",
    ").df()\n",
    "res = test\n",
    "res['predict'] = clf.predict(test.drop(columns = ['Date', 'Ticker', 'target']))\n",
    "\n",
    "db.sql(\n",
    "\"\"\"\n",
    "with prev_step as (\n",
    "    select *\n",
    "        , case when (target = 1) and (predict = 1) then date_trunc('month', Date) end as tp_month\n",
    "        , case when (target = 0) and (predict = 1) then date_trunc('month', Date) end as fp_month\n",
    "    from res\n",
    ")\n",
    ", result_agg_by_year_ticker as (\n",
    "    select \n",
    "        Ticker\n",
    "        , year(Date) as year\n",
    "        -- not working for some reason\n",
    "        --, count(distinct case when (target = 1) and (predict = 1) then date_trunc('month', Date) end) as TP\n",
    "        --, count(distinct case when (target = 0) and (predict = 1) then date_trunc('month', Date) end) as FP\n",
    "        , count(distinct tp_month) as TP\n",
    "        , count(distinct fp_month) as FP\n",
    "\n",
    "        --, sum(case when (target = 1) and (predict = 1) then 1 end) TP\n",
    "        --, sum(case when (target = 0) and (predict = 1) then 1 end) FP\n",
    "        \n",
    "        , TP/(TP+FP) as precision\n",
    "        , dense_rank() over (partition by year order by precision desc) as rnk \n",
    "    from prev_step\n",
    "    group by Ticker, year\n",
    ")\n",
    ", top_10_precise_each_year as (\n",
    "    select *\n",
    "    from result_agg_by_year_ticker\n",
    "    where rnk < 5\n",
    ")\n",
    "--select * from result_agg_by_year_ticker\n",
    "\n",
    "--select *\n",
    "--from result_agg_by_year_ticker\n",
    "--where tp != 0\n",
    "\n",
    "\n",
    "select Ticker, count(*) as cnt, sum(TP), sum(FP)\n",
    "from top_10_precise_each_year\n",
    "group by Ticker\n",
    "--having cnt > 2\n",
    "order by cnt desc, sum(TP) desc\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this approach have problem to do with: what if all the predictions are consecutive? this essentially would mean that it would be 1 opportunity instead of many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = db.sql(\"select * from feature_target where year(Date) in (2022)\").df()\n",
    "s_test = clf.score(test.drop(columns = ['Date', 'Ticker', 'target']),test['target'])\n",
    "print(s_test)\n",
    "#print(precision_score(test['target'],clf.predict(test.drop(columns = ['Date', 'Ticker', 'target']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"select * from full_df where gain_loss_ratio is null\").df()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
